{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LewdgsGB5ZJ6"},"outputs":[],"source":["!pip install kaggle\n","! mkdir ~/.kaggle\n","print(\"\\nOpen Kaggle Json API file for dataset download: \")\n","from google.colab import files\n","files.upload()\n","! mkdir ~/.kaggle\n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","! kaggle competitions download -c digit-recognizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDPND5Jv-ZzJ"},"outputs":[],"source":["import os\n","import sys\n","from tempfile import NamedTemporaryFile\n","from zipfile import ZipFile\n","import shutil\n","\n","CHUNK_SIZE = 40960\n","KAGGLE_INPUT_PATH='/kaggle/input'\n","KAGGLE_WORKING_PATH='/kaggle/working'\n","KAGGLE_SYMLINK='kaggle'\n","\n","shutil.rmtree('/kaggle/input', ignore_errors=True)\n","os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n","os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n","destination_path = os.path.join(KAGGLE_INPUT_PATH, \"\")\n","\n","with ZipFile('digit-recognizer.zip') as zfile:\n","  zfile.extractall(destination_path)\n","print('Data source import complete.')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"ke9cvddyxXiY","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"gDHiQyR0xXib","trusted":true},"outputs":[],"source":["np.random.seed(2)\n","torch.manual_seed(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"235c5900d1049bca329ba23de65ded75533d0a5a","id":"uB8fgcLSxXih","trusted":true},"outputs":[],"source":["from torchvision import datasets\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","from torch.optim import lr_scheduler\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image, ImageOps, ImageEnhance\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"788758e45eda228003a315930b02edf907f3cdae","id":"XMcEnQCixXik","trusted":true},"outputs":[],"source":["class dataset(Dataset):\n","    def __init__(self, file_path, transform=transforms.Compose([transforms.ToPILImage(),\n","                                                                transforms.ToTensor(),\n","                                                                transforms.Normalize(mean=(0.5,),\n","                                                                                     std=(0.5,))])):\n","        df = pd.read_csv(file_path)\n","        if len(df.columns)==n_pixels:\n","            self.X = df.values.reshape((-1, 28, 28)).astype(np.uint8)[:, :, :, None]\n","            self.y = None\n","        else:\n","            self.X = df.iloc[:, 1:].values.reshape((-1, 28, 28)).astype(np.uint8)[:, :, :, None]\n","            self.y = torch.from_numpy(df.iloc[:, 0].values)\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.transform(self.X[idx]), self.y[idx]\n","        return self.transform(self.X[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"03d712cf417d6444b1ab9576657527e0a1848987","id":"ohL36C5sxXin","trusted":true},"outputs":[],"source":["test_df = pd.read_csv('../input/test.csv')\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"e8294470265f0837ee00a38f7baa312a3be8536f","id":"UqCuyMojxXip","trusted":true},"outputs":[],"source":["n_pixels = len(test_df.columns)\n","n_pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"9c0257ed7cf2929152b35df876bada88d3ad6c59","id":"YN0N_ah3xXis","trusted":true},"outputs":[],"source":["num_workers = 0\n","batch_size = 64\n","transform = transforms.Compose([transforms.ToPILImage(), transforms.RandomRotation(degrees=20),\n","                                transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])\n","\n","train_dataset = dataset('../input/train.csv', transform=transform)\n","test_dataset = dataset('../input/test.csv')\n","train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"b4a2e4d9a99bc19a86d760f0c386a97ba907f48f","id":"Ov7w-OczxXiu","trusted":true},"outputs":[],"source":["dataiter = iter(train_dl)\n","images, labels = next(dataiter)\n","images = images.numpy()\n","\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(batch_size):\n","    ax = fig.add_subplot(2, int(batch_size/2), idx+1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n","    ax.set_title(str(labels[idx].item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a4b9ed25363b033fa543a4158dfd288b82fd8899","id":"z1eghsyJxXiw","trusted":true},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a30049b6a2aa69e256af14263fc9a6df18ad27a7","id":"JFghM-jJxXiz","trusted":true},"outputs":[],"source":["class ConvLayer(nn.Module):\n","    def __init__(self, in_channels=1, out_channels=256):\n","        super(ConvLayer, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=9, stride=1, padding=0)\n","    def forward(self, x):\n","        x = F.relu(self.conv(x))\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"1cdb6c8a20cabe8ae785ea4bceea1422e81afcbf","id":"C2HVqMpoxXi1","trusted":true},"outputs":[],"source":["class PrimaryCaps(nn.Module):\n","    def __init__(self, num_capsules=8, in_channels=256, out_channels=32):\n","        super(PrimaryCaps, self).__init__()\n","        self.capsules = nn.ModuleList([\n","            nn.Conv2d(in_channels, out_channels, kernel_size=9, stride=2, padding=0)\n","            for _ in range(num_capsules)\n","        ])\n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        u = [capsule(x).view(batch_size, 32*6*6, 1) for capsule in self.capsules]\n","        u = torch.cat(u, dim=-1)\n","        u_squashed = self.squash(u)\n","        return u_squashed\n","\n","    def squash(self, x):\n","        squared_norm = (x**2).sum(dim=-1, keepdim=True)\n","        scale = squared_norm/(1+squared_norm)\n","        output = scale * x/torch.sqrt(squared_norm)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3303b04fded4d9a75900e7cd9576b08ad214af5b","id":"CXs0ATWsxXi2","trusted":true},"outputs":[],"source":["def softmax(x, dim=1):\n","    transposed_inp = x.transpose(dim, len(x.size())-1)\n","    softmaxed = F.softmax(transposed_inp.contiguous().view(-1, transposed_inp.size(-1)), dim=-1)\n","    return softmaxed.view(*transposed_inp.size()).transpose(dim, len(x.size())-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"6cf5fe335649261c5b64e625872a3b6521290a88","id":"TEM0k_AqxXi3","trusted":true},"outputs":[],"source":["def dynamic_routing(b_ij, u_hat, squash, routing_iterations=3):\n","    for iterations in range(routing_iterations):\n","        c_ij = softmax(b_ij, dim=2)\n","        s_j = (c_ij*u_hat).sum(dim=2, keepdim=True)\n","        v_j = squash(s_j)\n","        if iterations < routing_iterations-1:\n","            a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\n","            b_ij = b_ij + a_ij\n","    return v_j"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"93f2c2a737ebe238037ef6e544c7534546fc5472","id":"9okX7yV-xXi4","trusted":true},"outputs":[],"source":["TRAIN_ON_GPU = torch.cuda.is_available()\n","if TRAIN_ON_GPU: print('training on gpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"7dc394aa7ea00415c98fceb762f0f88453d70308","id":"Wsy8aAeJxXi6","trusted":true},"outputs":[],"source":["class DigitCaps(nn.Module):\n","    def __init__(self, num_caps=10, previous_layer_nodes=32*6*6,\n","                 in_channels=8, out_channels=16):\n","        super(DigitCaps, self).__init__()\n","        self.num_caps = num_caps\n","        self.previous_layer_nodes = previous_layer_nodes\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        self.W = nn.Parameter(torch.randn(num_caps, previous_layer_nodes,\n","                                          in_channels, out_channels))\n","\n","    def forward(self, x):\n","        x = x[None, :, :, None, :]\n","        W = self.W[:, None, :, :, :]\n","        x_hat = torch.matmul(x, W)\n","        b_ij = torch.zeros(*x_hat.size())\n","        if TRAIN_ON_GPU: b_ij = b_ij.cuda()\n","        v_j = dynamic_routing(b_ij, x_hat, self.squash, routing_iterations=3)\n","        return v_j\n","\n","    def squash(self, x):\n","        squared_norm = (x**2).sum(dim=-1, keepdim=True)\n","        scale = squared_norm/(1+squared_norm)\n","        out = scale * x/torch.sqrt(squared_norm)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a029fe6c71e9280538fd20a8021fa26611f6a331","id":"FO6V67hLxXi8","trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, input_vector_length=16, input_capsules=10, hidden_dim=512):\n","        super(Decoder, self).__init__()\n","        input_dim = input_vector_length*input_capsules\n","        self.lin_layers = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(hidden_dim, hidden_dim*2),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(hidden_dim*2, 28*28),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        classes = (x**2).sum(dim=-1)**0.5\n","        classes = F.softmax(classes, dim=-1)\n","        _, max_length_indices = classes.max(dim=1)\n","        sparse_matrix = torch.eye(10)\n","        if TRAIN_ON_GPU: sparse_matrix = sparse_matrix.cuda()\n","        y = sparse_matrix.index_select(dim=0, index=max_length_indices.data)\n","        x = x*y[:, :, None]\n","        # flattened_x = x.view(x.size(0), -1)\n","        flattened_x = x.reshape(x.size(0), -1)\n","        reconstructed = self.lin_layers(flattened_x)\n","        return reconstructed, y"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"f6798b1acb1b4513ec0ad8d22c2ff3d15643dfe6","id":"_1Cbvoi3xXi9","trusted":true},"outputs":[],"source":["class CapsuleNetwork(nn.Module):\n","    def __init__(self):\n","        super(CapsuleNetwork, self).__init__()\n","        self.conv_layer = ConvLayer()\n","        self.primary_capsule = PrimaryCaps()\n","        self.digit_capsule = DigitCaps()\n","        self.decoder = Decoder()\n","    def forward(self, x):\n","        primary_caps_out = self.primary_capsule(self.conv_layer(x))\n","        caps_out = self.digit_capsule(primary_caps_out).squeeze().transpose(0, 1)\n","        reconstructed, y = self.decoder(caps_out)\n","        return caps_out, reconstructed, y"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"aa71d20627bcaef9f908cf8da2ce663a48845c6c","id":"ESpVqJCHxXi-","trusted":true},"outputs":[],"source":["capsule_net = CapsuleNetwork()\n","print(capsule_net)\n","if TRAIN_ON_GPU: capsule_net = capsule_net.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"00b2237913c40550e25e2c15c6cc54d06dda52f8","id":"zRJ7dGoKxXjA","trusted":true},"outputs":[],"source":["class CapsuleLoss(nn.Module):\n","    def __init__(self):\n","        super(CapsuleLoss, self).__init__()\n","        self.reconstruction_loss = nn.MSELoss(size_average=False)\n","\n","    def forward(self, x, labels, images, reconstructions):\n","        batch_size = x.size(0)\n","        v_c = torch.sqrt((x**2).sum(dim=2, keepdim=True))\n","        left = F.relu(0.9-v_c).view(batch_size, -1)\n","        right = F.relu(v_c-0.1).view(batch_size, -1)\n","        margin_loss = labels * left + 0.5 * (1.-labels) * right\n","        margin_loss = margin_loss.sum()\n","        images = images.view(reconstructions.size()[0], -1)\n","        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n","        return (margin_loss + 0.0005 * reconstruction_loss)/images.size(0)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"90e4dd28ac16df35dd220772c7703db818bf97cf","id":"jnTH-i97xXjB","trusted":true},"outputs":[],"source":["import torch.optim as optim\n","criterion = CapsuleLoss()\n","optimizer = optim.Adam(capsule_net.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"46a6963df16722a6b467bbbcb6d9525781684e61","id":"tl0poxjbxXjC","trusted":true},"outputs":[],"source":["def train(capsule_net, criterion, optimizer, n_epochs, print_every=300):\n","    losses = []\n","    for epoch in range(1, n_epochs+1):\n","        train_loss = 0.0\n","        capsule_net.train()\n","        for batch_i, (images, target) in enumerate(train_dl):\n","            target = torch.eye(10).index_select(dim=0, index=target)\n","            if TRAIN_ON_GPU: images, target = images.cuda(), target.cuda()\n","            optimizer.zero_grad()\n","            caps_output, reconstructions, y = capsule_net(images)\n","            loss = criterion(caps_output, target, images, reconstructions)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item()\n","            if batch_i != 0 and batch_i % print_every == 0:\n","                avg_train_loss = train_loss/print_every\n","                losses.append(avg_train_loss)\n","                print('Epoch: {} \\tTraining Loss: {:.8f}'.format(epoch, avg_train_loss))\n","                train_loss = 0\n","    return losses"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"3a12c81728eb48683380e5c9519e7557f045c788","id":"0rtEhooTxXjD","trusted":true},"outputs":[],"source":["n_epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"c714b512a5adc59654d23281f92508638e60d2b8","id":"D6jofSvxxXjF","trusted":true},"outputs":[],"source":["losses = train(capsule_net, criterion, optimizer, n_epochs=n_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ef442969ca2ee287c19f507096299e9bd04ba7fe","id":"0_hHBC0UxXjF","trusted":true},"outputs":[],"source":["plt.plot(losses)\n","plt.title('Training Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"ec305877f548c583897fab41e8d944cdcfce5b65","id":"NPsx3Q3qxXjL","trusted":true},"outputs":[],"source":["out = []\n","capsule_net.eval()\n","for image in test_dl:\n","    if TRAIN_ON_GPU: image = image.cuda()\n","    caps_out, reconstructed, y = capsule_net(image)\n","    _, pred = torch.max(y.data.cpu(), 1)\n","    out.extend(pred.numpy().tolist())\n","\n","len(out)\n","sub = pd.read_csv('../input/sample_submission.csv')\n","sub['Label'] = out\n","sub.to_csv('capsule.csv', index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}